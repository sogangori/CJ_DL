{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로의 데이터 포맷 : \n",
    "- (m, n) , m:데이터 갯수, n:특징 수\n",
    "- 시계열/시퀀스 데이터 : (m, t, n) , m:데이터 갯수, t:시간, n:특징 수 \n",
    "- 영상 (m, h, w, c) , (갯수,높이,너비,채널)    ,  CAFFE (m,c,h,w)\n",
    "- 커널 (h, w, c, m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(1, 10).reshape([1,3,3,1]).astype(np.float32)  \n",
    "x.dtype\n",
    "x[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맥스 풀링, ksize, stride = [2,2]  SAME(zero 패딩)  를 주로 사용합니다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.nn.max_pool(value=x, ksize=[2,2],strides=[2, 2], padding='SAME')#VALID or SAME, kernel = filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession() # .eval() 로 값을 바로 볼 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[5.],\n",
       "         [6.]],\n",
       "\n",
       "        [[8.],\n",
       "         [9.]]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel = np.arange(1,5).reshape([2,2,1,1]).astype(np.float32) #(h,w,c,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel[:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.nn.conv2d(x, kernel, strides=[1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[37., 47., 21.],\n",
       "        [67., 77., 33.],\n",
       "        [23., 26.,  9.]]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.eval()[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5, 12, 24, 36]), 77)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5,6,8,9]) * np.array([1,2,3,4]), np.sum(np.array([5,6,8,9]) * np.array([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape, mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (10000, 784))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x_train[1]\n",
    "x0_2d = x0.reshape([28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a56dfdc88>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(str(y_train[1]))\n",
    "plt.imshow(x0_2d, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.int32, [None]) # sparse_cross_entropy\n",
    "z = slim.fully_connected(X, 10)\n",
    "h = tf.nn.softmax(z) #z : logits, 가능성, 점수 \n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=z)#logits 은 softmax 하기 전의 값\n",
    "cost = tf.reduce_mean(cost)\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5775667, 0.8612)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10): # 에포크\n",
    "    _, _cost = sess.run([train, cost], {X:x_train, Y:y_train})\n",
    "p = np.argmax( sess.run(h, {X:x_train} ) , axis=-1)\n",
    "_cost, accuracy_score(y_train, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.argmax( sess.run(h, {X:x_test} ) , axis=-1)\n",
    "accuracy_score(y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       980\n",
      "           1       0.91      0.96      0.94      1135\n",
      "           2       0.89      0.83      0.86      1032\n",
      "           3       0.84      0.86      0.85      1010\n",
      "           4       0.86      0.88      0.87       982\n",
      "           5       0.87      0.73      0.80       892\n",
      "           6       0.88      0.92      0.90       958\n",
      "           7       0.90      0.88      0.89      1028\n",
      "           8       0.80      0.83      0.81       974\n",
      "           9       0.83      0.84      0.84      1009\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
